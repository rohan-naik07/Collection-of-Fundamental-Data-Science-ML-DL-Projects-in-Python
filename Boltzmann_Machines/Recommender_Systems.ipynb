{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recommender-Systems",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygl-QMxGrlM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLa_44GFgLsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movies=pd.read_csv('/content/sample_data/movies.dat',sep='::',header=None,engine='python',encoding='latin-1')\n",
        "users=pd.read_csv('/content/sample_data/users.dat',sep='::',header=None,engine='python',encoding='latin-1')\n",
        "ratings=pd.read_csv('/content/sample_data/ratings.dat',sep='::',header=None,engine='python',encoding='latin-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApTv4sfHgLig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set=pd.read_csv('/content/u1.base',delimiter='\\t')\n",
        "train_set=np.array(train_set,dtype='int')\n",
        "test_set=pd.read_csv('/content/u1.test',delimiter='\\t')\n",
        "test_set=np.array(test_set,dtype='int')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YiZnLe1gU_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_users= int(max(max(train_set[:,0]),max(test_set[:,0])))\n",
        "nb_movies= int(max(max(train_set[:,1]),max(test_set[:,1])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx3zDRVYgY_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# users in rows and movies in columns\n",
        "def convert(data):\n",
        "    new_data=[]\n",
        "    for id_users in range(1,nb_users+1):\n",
        "        id_movies= data[:,1][data[:,0]==id_users]\n",
        "        id_ratings= data[:,2][data[:,0]==id_users]\n",
        "        ratings=np.zeros(nb_movies)\n",
        "        ratings[id_movies-1]=id_ratings\n",
        "        new_data.append(ratings)\n",
        "    return new_data\n",
        "train_set=convert(train_set)\n",
        "test_set=convert(test_set)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpUmTedGh_ue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rePs9xlnh_j6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-rCD3pQgfaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set=torch.FloatTensor(train_set)\n",
        "test_set=torch.FloatTensor(test_set)\n",
        "\n",
        "train_set[train_set==0]=-1\n",
        "train_set[train_set==1]=0\n",
        "train_set[train_set==2]=-0\n",
        "train_set[train_set>=3]=1\n",
        "\n",
        "test_set[test_set==0]=-1\n",
        "test_set[test_set==1]=0\n",
        "test_set[test_set==2]=-0\n",
        "test_set[test_set>=3]=1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWizv3lMgl3P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RBM():\n",
        "    def __init__(self,nv,nh):\n",
        "        self.W=torch.randn(nv,nh)\n",
        "        self.a=torch.randn(1,nh) # bias for hidden nodes\n",
        "        self.b=torch.randn(1,nv) # bias for visible nodes\n",
        "\n",
        "    def sample_h(self,x):\n",
        "        wx=torch.mm(x,self.W)\n",
        "        activation=wx+self.a.expand_as(wx) #bias applied to each line of mini batch\n",
        "        ph_given_v=torch.sigmoid(activation)\n",
        "        return ph_given_v,torch.bernoulli(ph_given_v)\n",
        "\n",
        "    def sample_v(self,y):\n",
        "        wy=torch.mm(y,self.W.t())\n",
        "        activation=wy+self.b.expand_as(wy) #bias applied to each line of mini batch\n",
        "        pv_given_h=torch.sigmoid(activation)\n",
        "        return pv_given_h,torch.bernoulli(pv_given_h)\n",
        "\n",
        "    def train(self,v0,vk,ph0,phk):\n",
        "        self.W+=torch.mm(v0.t(),ph0)-torch.mm(vk.t(),phk)\n",
        "        self.b+=torch.sum((v0-vk),0)\n",
        "        self.a+=torch.sum((ph0-phk),0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9b5tH8rgq0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nv=len(train_set[0])\n",
        "nh= 100 # no of features we want to detect\n",
        "batch_size=100\n",
        "model=RBM(nv=nv,nh=nh)\n",
        "no_of_epochs=30"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9YX3ZaFrZEd",
        "colab_type": "code",
        "outputId": "7642c5bb-eaff-4385-b424-928490599b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "for epoch in range(1,no_of_epochs+1):\n",
        "    train_loss=0\n",
        "    s=0.\n",
        "    for id_user in range(0,nb_users-batch_size,batch_size):\n",
        "        vk=train_set[id_user:id_user+batch_size] \n",
        "        v0=train_set[id_user:id_user+batch_size]\n",
        "        ph0,_= model.sample_h(v0)\n",
        "        for k in range(10):\n",
        "            _,hk=model.sample_h(vk) # features from movies\n",
        "            _,vk=model.sample_v(hk) # movies from extracted features\n",
        "            vk[v0 < 0] = v0[v0<0]\n",
        "        phk,_=model.sample_h(vk) \n",
        "        #print(v0.shape,vk.shape,ph0.shape,phk.shape) \n",
        "        model.train(v0,vk,ph0,phk)\n",
        "        train_loss+=torch.mean(torch.abs(v0[v0 >= 0]-vk[v0 >=0]))\n",
        "        s+=1.\n",
        "    print('loss after epoch '+str(epoch) +' is '+str(train_loss/s))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss after epoch 1 is tensor(0.3466)\n",
            "loss after epoch 2 is tensor(0.2580)\n",
            "loss after epoch 3 is tensor(0.2097)\n",
            "loss after epoch 4 is tensor(0.2441)\n",
            "loss after epoch 5 is tensor(0.2438)\n",
            "loss after epoch 6 is tensor(0.2475)\n",
            "loss after epoch 7 is tensor(0.2466)\n",
            "loss after epoch 8 is tensor(0.2447)\n",
            "loss after epoch 9 is tensor(0.2469)\n",
            "loss after epoch 10 is tensor(0.2454)\n",
            "loss after epoch 11 is tensor(0.2470)\n",
            "loss after epoch 12 is tensor(0.2452)\n",
            "loss after epoch 13 is tensor(0.2448)\n",
            "loss after epoch 14 is tensor(0.2443)\n",
            "loss after epoch 15 is tensor(0.2436)\n",
            "loss after epoch 16 is tensor(0.2444)\n",
            "loss after epoch 17 is tensor(0.2454)\n",
            "loss after epoch 18 is tensor(0.2457)\n",
            "loss after epoch 19 is tensor(0.2450)\n",
            "loss after epoch 20 is tensor(0.2467)\n",
            "loss after epoch 21 is tensor(0.2432)\n",
            "loss after epoch 22 is tensor(0.2441)\n",
            "loss after epoch 23 is tensor(0.2462)\n",
            "loss after epoch 24 is tensor(0.2449)\n",
            "loss after epoch 25 is tensor(0.2459)\n",
            "loss after epoch 26 is tensor(0.2438)\n",
            "loss after epoch 27 is tensor(0.2443)\n",
            "loss after epoch 28 is tensor(0.2462)\n",
            "loss after epoch 29 is tensor(0.2441)\n",
            "loss after epoch 30 is tensor(0.2454)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGvHmkkGri6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_loss=0\n",
        "s=0.\n",
        "for id_user in range(0,nb_users):\n",
        "    v=train_set[id_user:id_user+1] \n",
        "    vt=test_set[id_user:id_user+1]\n",
        "    if len(vt[vt>=0]) >0:\n",
        "        _,h=model.sample_h(v) # features from movies\n",
        "        _,v=model.sample_v(h) # movies from extracted \n",
        "        print(v)\n",
        "        test_loss+=torch.mean(torch.abs(v[vt >= 0]-vt[vt >=0]))\n",
        "        s+=1.\n",
        "print('loss is '+str(test_loss/s))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apKSDAfZllXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}